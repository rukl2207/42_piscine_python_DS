{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 09. Exercise 00\n",
    "# Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, plot_confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Read the file `dayofweek.csv` that you used in the previous day to a dataframe.\n",
    "2. Using `train_test_split` with parameters `test_size=0.2`, `random_state=21` get `X_train`, `y_train`, `X_test`, `y_test`. Use the additional parameter `stratify`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>numTrials</th>\n",
       "      <th>hour</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>uid_user_0</th>\n",
       "      <th>uid_user_1</th>\n",
       "      <th>uid_user_10</th>\n",
       "      <th>uid_user_11</th>\n",
       "      <th>uid_user_12</th>\n",
       "      <th>uid_user_13</th>\n",
       "      <th>uid_user_14</th>\n",
       "      <th>...</th>\n",
       "      <th>labname_lab02</th>\n",
       "      <th>labname_lab03</th>\n",
       "      <th>labname_lab03s</th>\n",
       "      <th>labname_lab05s</th>\n",
       "      <th>labname_laba04</th>\n",
       "      <th>labname_laba04s</th>\n",
       "      <th>labname_laba05</th>\n",
       "      <th>labname_laba06</th>\n",
       "      <th>labname_laba06s</th>\n",
       "      <th>labname_project1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.788667</td>\n",
       "      <td>-2.562352</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.756764</td>\n",
       "      <td>-2.562352</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.724861</td>\n",
       "      <td>-2.562352</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.692958</td>\n",
       "      <td>-2.562352</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.661055</td>\n",
       "      <td>-2.562352</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1681</th>\n",
       "      <td>-0.533442</td>\n",
       "      <td>0.945382</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1682</th>\n",
       "      <td>-0.629151</td>\n",
       "      <td>0.945382</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1683</th>\n",
       "      <td>-0.597248</td>\n",
       "      <td>0.945382</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1684</th>\n",
       "      <td>-0.565345</td>\n",
       "      <td>0.945382</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1685</th>\n",
       "      <td>-0.533442</td>\n",
       "      <td>0.945382</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1686 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      numTrials      hour  dayofweek  uid_user_0  uid_user_1  uid_user_10  \\\n",
       "0     -0.788667 -2.562352          4           0           0            0   \n",
       "1     -0.756764 -2.562352          4           0           0            0   \n",
       "2     -0.724861 -2.562352          4           0           0            0   \n",
       "3     -0.692958 -2.562352          4           0           0            0   \n",
       "4     -0.661055 -2.562352          4           0           0            0   \n",
       "...         ...       ...        ...         ...         ...          ...   \n",
       "1681  -0.533442  0.945382          3           0           0            0   \n",
       "1682  -0.629151  0.945382          3           0           1            0   \n",
       "1683  -0.597248  0.945382          3           0           1            0   \n",
       "1684  -0.565345  0.945382          3           0           1            0   \n",
       "1685  -0.533442  0.945382          3           0           1            0   \n",
       "\n",
       "      uid_user_11  uid_user_12  uid_user_13  uid_user_14  ...  labname_lab02  \\\n",
       "0               0            0            0            0  ...              0   \n",
       "1               0            0            0            0  ...              0   \n",
       "2               0            0            0            0  ...              0   \n",
       "3               0            0            0            0  ...              0   \n",
       "4               0            0            0            0  ...              0   \n",
       "...           ...          ...          ...          ...  ...            ...   \n",
       "1681            0            0            0            0  ...              0   \n",
       "1682            0            0            0            0  ...              0   \n",
       "1683            0            0            0            0  ...              0   \n",
       "1684            0            0            0            0  ...              0   \n",
       "1685            0            0            0            0  ...              0   \n",
       "\n",
       "      labname_lab03  labname_lab03s  labname_lab05s  labname_laba04  \\\n",
       "0                 0               0               0               0   \n",
       "1                 0               0               0               0   \n",
       "2                 0               0               0               0   \n",
       "3                 0               0               0               0   \n",
       "4                 0               0               0               0   \n",
       "...             ...             ...             ...             ...   \n",
       "1681              0               0               0               0   \n",
       "1682              0               0               0               0   \n",
       "1683              0               0               0               0   \n",
       "1684              0               0               0               0   \n",
       "1685              0               0               0               0   \n",
       "\n",
       "      labname_laba04s  labname_laba05  labname_laba06  labname_laba06s  \\\n",
       "0                   0               0               0                0   \n",
       "1                   0               0               0                0   \n",
       "2                   0               0               0                0   \n",
       "3                   0               0               0                0   \n",
       "4                   0               0               0                0   \n",
       "...               ...             ...             ...              ...   \n",
       "1681                0               0               0                1   \n",
       "1682                0               0               0                1   \n",
       "1683                0               0               0                1   \n",
       "1684                0               0               0                1   \n",
       "1685                0               0               0                1   \n",
       "\n",
       "      labname_project1  \n",
       "0                    1  \n",
       "1                    1  \n",
       "2                    1  \n",
       "3                    1  \n",
       "4                    1  \n",
       "...                ...  \n",
       "1681                 0  \n",
       "1682                 0  \n",
       "1683                 0  \n",
       "1684                 0  \n",
       "1685                 0  \n",
       "\n",
       "[1686 rows x 44 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/dayofweek.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop('dayofweek', axis=1)\n",
    "y = df['dayofweek']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=21, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Logreg regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Default regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Train a baseline model with the only parameters `random_state=21`, `fit_intercept=False`.\n",
    "2. Use stratified K-fold cross-validation with `10` splits to evaluate the accuracy of the model\n",
    "\n",
    "\n",
    "The result of the code where you trained and evaluated the baseline model should be exactly like this (use `%%time` to get the info about how long it took to run the cell):\n",
    "\n",
    "```\n",
    "train -  0.62902   |   valid -  0.59259\n",
    "train -  0.64633   |   valid -  0.62963\n",
    "train -  0.63479   |   valid -  0.56296\n",
    "train -  0.65622   |   valid -  0.61481\n",
    "train -  0.63397   |   valid -  0.57778\n",
    "train -  0.64056   |   valid -  0.59259\n",
    "train -  0.64138   |   valid -  0.65926\n",
    "train -  0.65952   |   valid -  0.56296\n",
    "train -  0.64333   |   valid -  0.59701\n",
    "train -  0.63674   |   valid -  0.62687\n",
    "Average accuracy on crossval is 0.60165\n",
    "Std is 0.02943\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(fit_intercept=False, random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossval(estimator, X, y, n_splits=10):\n",
    "    train_scores = []\n",
    "    valid_scores = []\n",
    "    cv = StratifiedKFold(n_splits=n_splits)\n",
    "    for train, valid in cv.split(X, y):\n",
    "        estimator.fit(X.iloc[train], y.iloc[train])\n",
    "        y_train_pred = estimator.predict(X.iloc[train])\n",
    "        y_valid_pred = estimator.predict(X.iloc[valid])\n",
    "        train_scores.append(accuracy_score(y.iloc[train], y_train_pred))\n",
    "        valid_scores.append(accuracy_score(y.iloc[valid], y_valid_pred))\n",
    "    for i in range(len(train_scores)):\n",
    "        print(f'train -  {train_scores[i]:.5f}   |   valid -  {valid_scores[i]:.5f}')\n",
    "    print(f'Average accuracy on crossval is {np.mean(valid_scores):.5f}')\n",
    "    print(f'Std is {np.std(valid_scores):.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train -  0.62902   |   valid -  0.59259\n",
      "train -  0.64633   |   valid -  0.62963\n",
      "train -  0.63479   |   valid -  0.56296\n",
      "train -  0.65622   |   valid -  0.61481\n",
      "train -  0.63397   |   valid -  0.57778\n",
      "train -  0.64056   |   valid -  0.59259\n",
      "train -  0.64138   |   valid -  0.65926\n",
      "train -  0.65952   |   valid -  0.56296\n",
      "train -  0.64333   |   valid -  0.59701\n",
      "train -  0.63674   |   valid -  0.62687\n",
      "Average accuracy on crossval is 0.60165\n",
      "Std is 0.02943\n",
      "CPU times: user 1.31 s, sys: 959 ms, total: 2.27 s\n",
      "Wall time: 883 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "crossval(lr, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Optimizing regularization parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In the cells below try different values of penalty: `none`, `l1`, `l2` – you can change the values of solver too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/scornhol/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/Users/scornhol/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/Users/scornhol/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/Users/scornhol/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/Users/scornhol/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/Users/scornhol/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/Users/scornhol/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/Users/scornhol/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/Users/scornhol/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/Users/scornhol/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/Users/scornhol/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/Users/scornhol/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/Users/scornhol/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/Users/scornhol/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/Users/scornhol/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/Users/scornhol/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/Users/scornhol/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/Users/scornhol/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/Users/scornhol/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/Users/scornhol/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/Users/scornhol/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/Users/scornhol/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/Users/scornhol/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/Users/scornhol/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/Users/scornhol/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/Users/scornhol/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=LogisticRegression(fit_intercept=False, random_state=21),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{'penalty': ['l1', 'l2'],\n",
       "                          'solver': ['liblinear', 'saga']},\n",
       "                         {'penalty': ['l1', 'l2', 'none'], 'solver': ['saga']},\n",
       "                         {'penalty': ['l2', 'none'],\n",
       "                          'solver': ['newton-cg', 'lbfgs', 'sag']}],\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = [\n",
    "              {'solver': ['liblinear', 'saga'], 'penalty': ['l1', 'l2']},\n",
    "              {'solver': ['saga'], 'penalty': ['l1', 'l2', 'none']},\n",
    "              {'solver': ['newton-cg', 'lbfgs', 'sag'], 'penalty': ['l2', 'none']}]\n",
    "\n",
    "gs = GridSearchCV(lr, param_grid, scoring='accuracy', n_jobs=-1)\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'penalty': 'none', 'solver': 'sag'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6313314057551975"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. SVM regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Default regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Train a baseline model with the only parameters `probability=True`, `kernel='linear'`, `random_state=21`.\n",
    "2. Use stratified K-fold cross-validation with `10` splits to evaluate the accuracy of the model.\n",
    "3. The format of the result of the code where you trained and evaluated the baseline model should be similar to what you have got for the logreg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(kernel='linear', probability=True, random_state=21)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train -  0.70486   |   valid -  0.65926\n",
      "train -  0.69662   |   valid -  0.75556\n",
      "train -  0.69415   |   valid -  0.62222\n",
      "train -  0.70239   |   valid -  0.65185\n",
      "train -  0.69085   |   valid -  0.65185\n",
      "train -  0.68920   |   valid -  0.64444\n",
      "train -  0.69250   |   valid -  0.72593\n",
      "train -  0.70074   |   valid -  0.62222\n",
      "train -  0.69605   |   valid -  0.61940\n",
      "train -  0.71087   |   valid -  0.63433\n",
      "Average accuracy on crossval is 0.65871\n",
      "Std is 0.04359\n",
      "CPU times: user 3.41 s, sys: 15.7 ms, total: 3.42 s\n",
      "Wall time: 3.44 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "crossval(svc, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Optimizing regularization parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In the cells below try different values of the parameter `C`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(kernel='linear', probability=True, random_state=21),\n",
       "             n_jobs=-1, param_grid={'C': [15, 40, 60, 100, 150]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'C': [15, 40, 60, 100, 150]}\n",
    "gs = GridSearchCV(svc, param_grid, scoring='accuracy', n_jobs=-1)\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 100}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7403662398457937"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Default regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Train a baseline model with the only parameter `max_depth=10` and `random_state=21`.\n",
    "2. Use stratified K-fold cross-validation with `10` splits to evaluate the accuracy of the model.\n",
    "3. The format of the result of the code where you trained and evaluated the baseline model should be similar to what you have got for the logreg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier(max_depth=10, random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train -  0.81039   |   valid -  0.74074\n",
      "train -  0.77741   |   valid -  0.74074\n",
      "train -  0.83347   |   valid -  0.70370\n",
      "train -  0.79720   |   valid -  0.76296\n",
      "train -  0.82440   |   valid -  0.75556\n",
      "train -  0.80379   |   valid -  0.68889\n",
      "train -  0.80709   |   valid -  0.76296\n",
      "train -  0.80132   |   valid -  0.65926\n",
      "train -  0.80807   |   valid -  0.75373\n",
      "train -  0.80478   |   valid -  0.68657\n",
      "Average accuracy on crossval is 0.72551\n",
      "Std is 0.03562\n",
      "CPU times: user 83.4 ms, sys: 2.83 ms, total: 86.3 ms\n",
      "Wall time: 87.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "crossval(dtc, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Optimizing regularization parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In the cells below try different values of the parameter `max_depth`.\n",
    "2. As a bonus, play with other regularization parameters trying to find the best combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=DecisionTreeClassifier(max_depth=10, random_state=21),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'max_depth': array([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "       19, 20, 21, 22, 23, 24]),\n",
       "                         'splitter': ['best', 'random']},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'splitter': ['best', 'random'],\n",
    "              'max_depth': np.arange(2, 25)}\n",
    "gs = GridSearchCV(dtc, param_grid, scoring='accuracy', n_jobs=-1)\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 21, 'splitter': 'random'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8716590940382762"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Default regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Train a baseline model with the only parameters `n_estimators=50`, `max_depth=14`, `random_state=21`.\n",
    "2. Use stratified K-fold cross-validation with `10` splits to evaluate the accuracy of the model.\n",
    "3. The format of the result of the code where you trained and evaluated the baseline model should be similar to what you have got for the logreg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=50, max_depth=14, random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train -  0.96455   |   valid -  0.88148\n",
      "train -  0.96208   |   valid -  0.91852\n",
      "train -  0.96785   |   valid -  0.86667\n",
      "train -  0.96455   |   valid -  0.89630\n",
      "train -  0.96538   |   valid -  0.91111\n",
      "train -  0.96538   |   valid -  0.88148\n",
      "train -  0.97115   |   valid -  0.91852\n",
      "train -  0.96867   |   valid -  0.85185\n",
      "train -  0.97364   |   valid -  0.88060\n",
      "train -  0.97941   |   valid -  0.86567\n",
      "Average accuracy on crossval is 0.88722\n",
      "Std is 0.02204\n",
      "CPU times: user 968 ms, sys: 14.3 ms, total: 982 ms\n",
      "Wall time: 986 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "crossval(rfc, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Optimizing regularization parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In the new cells try different values of the parameters `max_depth` and `n_estimators`.\n",
    "2. As a bonus, play with other regularization parameters trying to find the best combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=RandomForestClassifier(max_depth=14, n_estimators=50,\n",
       "                                              random_state=21),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'max_depth': array([15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       "                         'max_features': ['auto', 'sqrt', 'log2'],\n",
       "                         'n_estimators': array([ 50,  51,  52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,\n",
       "        63,  64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,\n",
       "        76,  77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,\n",
       "        89,  90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101,\n",
       "       102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114,\n",
       "       115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127,\n",
       "       128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140,\n",
       "       141, 142, 143, 144, 145, 146, 147, 148, 149])},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'max_features': ['auto', 'sqrt', 'log2'],\n",
    "              'max_depth': np.arange(15, 30),\n",
    "              'n_estimators': np.arange(50, 150)}\n",
    "gs = GridSearchCV(rfc, param_grid, scoring='accuracy', n_jobs=-1)\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 27, 'max_features': 'auto', 'n_estimators': 147}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9042929918766351"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Choose the best model and use it to make predictions for the test dataset.\n",
    "2. Calculate the final accuracy.\n",
    "3. Analyze: for which weekday your model makes the most errors (in % of the total number of samples of that class in your test dataset).\n",
    "4. Save the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "y_pred = gs.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9319526627218935"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7ff9873bf050>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ConfusionMatrixDisplay.from_estimator(gs.best_estimator_, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/model.joblib']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(gs.best_estimator_, '../data/model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
